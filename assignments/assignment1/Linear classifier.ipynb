{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Задание 1.2 - Линейный классификатор (Linear classifier)\n",
    "\n",
    "В этом задании мы реализуем другую модель машинного обучения - линейный классификатор. Линейный классификатор подбирает для каждого класса веса, на которые нужно умножить значение каждого признака и потом сложить вместе.\n",
    "Тот класс, у которого эта сумма больше, и является предсказанием модели.\n",
    "\n",
    "В этом задании вы:\n",
    "- потренируетесь считать градиенты различных многомерных функций\n",
    "- реализуете подсчет градиентов через линейную модель и функцию потерь softmax\n",
    "- реализуете процесс тренировки линейного классификатора\n",
    "- подберете параметры тренировки на практике\n",
    "\n",
    "На всякий случай, еще раз ссылка на туториал по numpy:  \n",
    "http://cs231n.github.io/python-numpy-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_gradient\n",
    "from metrics import multiclass_accuracy \n",
    "import linear_classifer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Как всегда, первым делом загружаем данные\n",
    "\n",
    "Мы будем использовать все тот же SVHN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def prepare_for_linear_classifier(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(float) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(float) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    # Add another channel with ones as a bias term\n",
    "    train_flat_with_ones = np.hstack([train_flat, np.ones((train_X.shape[0], 1))])\n",
    "    test_flat_with_ones = np.hstack([test_flat, np.ones((test_X.shape[0], 1))])    \n",
    "    return train_flat_with_ones, test_flat_with_ones\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_linear_classifier(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Играемся с градиентами!\n",
    "\n",
    "В этом курсе мы будем писать много функций, которые вычисляют градиенты аналитическим методом.\n",
    "\n",
    "Все функции, в которых мы будем вычислять градиенты, будут написаны по одной и той же схеме.  \n",
    "Они будут получать на вход точку, где нужно вычислить значение и градиент функции, а на выходе будут выдавать кортеж (tuple) из двух значений - собственно значения функции в этой точке (всегда одно число) и аналитического значения градиента в той же точке (той же размерности, что и вход).\n",
    "```\n",
    "def f(x):\n",
    "    \"\"\"\n",
    "    Computes function and analytic gradient at x\n",
    "    \n",
    "    x: np array of float, input to the function\n",
    "    \n",
    "    Returns:\n",
    "    value: float, value of the function \n",
    "    grad: np array of float, same shape as x\n",
    "    \"\"\"\n",
    "    ...\n",
    "    \n",
    "    return value, grad\n",
    "```\n",
    "\n",
    "Необходимым инструментом во время реализации кода, вычисляющего градиенты, является функция его проверки. Эта функция вычисляет градиент численным методом и сверяет результат с градиентом, вычисленным аналитическим методом.\n",
    "\n",
    "Мы начнем с того, чтобы реализовать вычисление численного градиента (numeric gradient) в функции `check_gradient` в `gradient_check.py`. Эта функция будет принимать на вход функции формата, заданного выше, использовать значение `value` для вычисления численного градиента и сравнит его с аналитическим - они должны сходиться.\n",
    "\n",
    "Напишите часть функции, которая вычисляет градиент с помощью численной производной для каждой координаты. Для вычисления производной используйте так называемую two-point formula (https://en.wikipedia.org/wiki/Numerical_differentiation):\n",
    "\n",
    "<img alt=\"image\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/22fc2c0a66c63560a349604f8b6b39221566236d\"/>\n",
    "\n",
    "Все функции приведенные в следующей клетке должны проходить gradient check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Implement check_gradient function in gradient_check.py\n",
    "# All the functions below should pass the gradient check\n",
    "\n",
    "def square(x):\n",
    "    return float(x*x), 2*x\n",
    "\n",
    "check_gradient(square, np.array([3.0]))\n",
    "\n",
    "def array_sum(x):\n",
    "    assert x.shape == (2,), x.shape\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_sum, np.array([3.0, 2.0]))\n",
    "\n",
    "def array_2d_sum(x):\n",
    "    assert x.shape == (2,2)\n",
    "    return np.sum(x), np.ones_like(x)\n",
    "\n",
    "check_gradient(array_2d_sum, np.array([[3.0, 2.0], [1.0, 0.0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Начинаем писать свои функции, считающие аналитический градиент\n",
    "\n",
    "Теперь реализуем функцию softmax, которая получает на вход оценки для каждого класса и преобразует их в вероятности от 0 до 1:\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/e348290cf48ddbb6e9a6ef4e39363568b67c09d3)\n",
    "\n",
    "**Важно:** Практический аспект вычисления этой функции заключается в том, что в ней учавствует вычисление экспоненты от потенциально очень больших чисел - это может привести к очень большим значениям в числителе и знаменателе за пределами диапазона float.\n",
    "\n",
    "К счастью, у этой проблемы есть простое решение -- перед вычислением softmax вычесть из всех оценок максимальное значение среди всех оценок:\n",
    "```\n",
    "predictions -= np.max(predictions)\n",
    "```\n",
    "(подробнее здесь - http://cs231n.github.io/linear-classify/#softmax, секция `Practical issues: Numeric stability`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO Implement softmax and cross-entropy for single sample\n",
    "probs = linear_classifer.softmax(np.array([-10, 0, 10]))\n",
    "\n",
    "# Make sure it works for big numbers too!\n",
    "probs = linear_classifer.softmax(np.array([1000, 0, 0]))\n",
    "assert np.isclose(probs[0], 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Кроме этого, мы реализуем cross-entropy loss, которую мы будем использовать как функцию ошибки (error function).\n",
    "В общем виде cross-entropy определена следующим образом:\n",
    "![image](https://wikimedia.org/api/rest_v1/media/math/render/svg/0cb6da032ab424eefdca0884cd4113fe578f4293)\n",
    "\n",
    "где x - все классы, p(x) - истинная вероятность принадлежности сэмпла классу x, а q(x) - вероятность принадлежности классу x, предсказанная моделью.  \n",
    "В нашем случае сэмпл принадлежит только одному классу, индекс которого передается функции. Для него p(x) равна 1, а для остальных классов - 0. \n",
    "\n",
    "Это позволяет реализовать функцию проще!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "5.006760443547122"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = linear_classifer.softmax(np.array([-5, 0, 5]))\n",
    "linear_classifer.cross_entropy_loss(probs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([4.50940412e-05, 6.69254912e-03, 9.93262357e-01])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "После того как мы реализовали сами функции, мы можем реализовать градиент.\n",
    "\n",
    "Оказывается, что вычисление градиента становится гораздо проще, если объединить эти функции в одну, которая сначала вычисляет вероятности через softmax, а потом использует их для вычисления функции ошибки через cross-entropy loss.\n",
    "\n",
    "Эта функция `softmax_with_cross_entropy` будет возвращает и значение ошибки, и градиент по входным параметрам. Мы проверим корректность реализации с помощью `check_gradient`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\Temp/ipykernel_11300/979710720.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, 1), np.array([1, 0, 0], np.float))\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement combined function or softmax and cross entropy and produces gradient\n",
    "loss, grad = linear_classifer.softmax_with_cross_entropy(np.array([1, 0, 0]), 1)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, 1), np.array([1, 0, 0], np.float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "В качестве метода тренировки мы будем использовать стохастический градиентный спуск (stochastic gradient descent или SGD), который работает с батчами сэмплов. \n",
    "\n",
    "Поэтому все наши фукнции будут получать не один пример, а батч, то есть входом будет не вектор из `num_classes` оценок, а матрица размерности `batch_size, num_classes`. Индекс примера в батче всегда будет первым измерением.\n",
    "\n",
    "Следующий шаг - переписать наши функции так, чтобы они поддерживали батчи.\n",
    "\n",
    "Финальное значение функции ошибки должно остаться числом, и оно равно среднему значению ошибки среди всех примеров в батче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "predictions = np.array([[2., -1, -1. , 1],[0., 1., 1., 1.],[1.,2.,-1., 2.]])\n",
    "target_index = np.array([[3],[3], [2]])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.480614761850989\n",
      "Gradient check passed!\n",
      "5.177536162336642\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# # TODO Extend combined function so it can receive a 2d array with batch of samples\n",
    "np.random.seed(42)\n",
    "# Test batch_size = 1\n",
    "num_classes = 4\n",
    "batch_size = 1\n",
    "# predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(float)\n",
    "probs = linear_classifer.softmax(predictions)\n",
    "\n",
    "target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(int)\n",
    "\n",
    "loss = linear_classifer.cross_entropy_loss(probs=probs, target_index=target_index)\n",
    "print(loss)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)\n",
    "\n",
    "# Test batch_size = 3\n",
    "num_classes = 4\n",
    "batch_size = 3\n",
    "predictions = np.random.randint(-1, 3, size=(batch_size, num_classes)).astype(float)\n",
    "target_index = np.random.randint(0, num_classes, size=(batch_size, 1)).astype(int)\n",
    "\n",
    "\n",
    "probs = linear_classifer.softmax(predictions)\n",
    "probs_calc = probs.copy()\n",
    "loss = linear_classifer.cross_entropy_loss(probs=probs, target_index=target_index)\n",
    "print(loss)\n",
    "check_gradient(lambda x: linear_classifer.softmax_with_cross_entropy(x, target_index), predictions)\n",
    "\n",
    "# Make sure maximum subtraction for numberic stability is done separately for every sample in the batch\n",
    "probs = linear_classifer.softmax(np.array([[20,0,0], [1000, 0, 0]]))\n",
    "assert np.all(np.isclose(probs[:, 0], 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "true_probs = np.zeros_like(predictions)\n",
    "np.put_along_axis(true_probs, target_index.reshape(-1,1), 1, axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Наконец, реализуем сам линейный классификатор!\n",
    "\n",
    "softmax и cross-entropy получают на вход оценки, которые выдает линейный классификатор.\n",
    "\n",
    "Он делает это очень просто: для каждого класса есть набор весов, на которые надо умножить пиксели картинки и сложить. Получившееся число и является оценкой класса, идущей на вход softmax.\n",
    "\n",
    "Таким образом, линейный классификатор можно представить как умножение вектора с пикселями на матрицу W размера `num_features, num_classes`. Такой подход легко расширяется на случай батча векторов с пикселями X размера `batch_size, num_features`:\n",
    "\n",
    "`predictions = X * W`, где `*` - матричное умножение.\n",
    "\n",
    "Реализуйте функцию подсчета линейного классификатора и градиентов по весам `linear_softmax` в файле `linear_classifer.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Denis\\AppData\\Local\\Temp/ipykernel_11300/1919402437.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  W = np.random.randint(-1, 3, size=(num_features, num_classes)).astype(np.float)\n",
      "C:\\Users\\Denis\\AppData\\Local\\Temp/ipykernel_11300/1919402437.py:7: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X = np.random.randint(-1, 3, size=(batch_size, num_features)).astype(np.float)\n",
      "C:\\Users\\Denis\\AppData\\Local\\Temp/ipykernel_11300/1919402437.py:8: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  target_index = np.ones(batch_size, dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement linear_softmax function that uses softmax with cross-entropy for linear classifier\n",
    "batch_size = 2\n",
    "num_classes = 2\n",
    "num_features = 3\n",
    "np.random.seed(42)\n",
    "W = np.random.randint(-1, 3, size=(num_features, num_classes)).astype(np.float)\n",
    "X = np.random.randint(-1, 3, size=(batch_size, num_features)).astype(np.float)\n",
    "target_index = np.ones(batch_size, dtype=np.int)\n",
    "\n",
    "loss, dW = linear_classifer.linear_softmax(X, W, target_index)\n",
    "check_gradient(lambda w: linear_classifer.linear_softmax(X, w, target_index), W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(3, 2)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### И теперь регуляризация\n",
    "\n",
    "Мы будем использовать L2 regularization для весов как часть общей функции ошибки.\n",
    "\n",
    "Напомним, L2 regularization определяется как\n",
    "\n",
    "l2_reg_loss = regularization_strength * sum<sub>ij</sub> W[i, j]<sup>2</sup>\n",
    "\n",
    "Реализуйте функцию для его вычисления и вычисления соотвествующих градиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Implement l2_regularization function that implements loss for L2 regularization\n",
    "linear_classifer.l2_regularization(W, 0.01)\n",
    "check_gradient(lambda w: linear_classifer.l2_regularization(w, 0.01), W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Тренировка!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Градиенты в порядке, реализуем процесс тренировки!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 230068.962378\n",
      "Epoch 1, loss: 263187.952045\n",
      "Epoch 2, loss: 263205.987064\n",
      "Epoch 3, loss: 252930.857069\n",
      "Epoch 4, loss: 267046.091269\n",
      "Epoch 5, loss: 251001.052876\n",
      "Epoch 6, loss: 256601.745461\n",
      "Epoch 7, loss: 245353.382807\n",
      "Epoch 8, loss: 251270.650236\n",
      "Epoch 9, loss: 266806.338577\n",
      "Epoch 10, loss: 259815.137222\n",
      "Epoch 11, loss: 272486.349359\n",
      "Epoch 12, loss: 239413.272622\n",
      "Epoch 13, loss: 249278.658724\n",
      "Epoch 14, loss: 258673.298530\n",
      "Epoch 15, loss: 281180.472405\n",
      "Epoch 16, loss: 245470.089049\n",
      "Epoch 17, loss: 237962.884973\n",
      "Epoch 18, loss: 249993.603039\n",
      "Epoch 19, loss: 262282.116970\n",
      "Epoch 20, loss: 234680.813707\n",
      "Epoch 21, loss: 256765.631005\n",
      "Epoch 22, loss: 266749.362151\n",
      "Epoch 23, loss: 248760.913465\n",
      "Epoch 24, loss: 269517.078234\n",
      "Epoch 25, loss: 245686.512984\n",
      "Epoch 26, loss: 251999.293823\n",
      "Epoch 27, loss: 244813.457242\n",
      "Epoch 28, loss: 254664.476201\n",
      "Epoch 29, loss: 274214.327014\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement LinearSoftmaxClassifier.fit function\n",
    "classifier = linear_classifer.LinearSoftmaxClassifier()\n",
    "loss_history = classifier.fit(train_X, train_y, epochs=30, learning_rate=1e-2, batch_size=300, reg=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x1ebb20a6610>]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# let's look at the loss history!\n",
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.251\n",
      "Epoch 0, loss: 17610.052573\n",
      "Epoch 1, loss: 17595.643856\n",
      "Epoch 2, loss: 17585.758585\n",
      "Epoch 3, loss: 17574.406783\n",
      "Epoch 4, loss: 17562.907681\n",
      "Epoch 5, loss: 17556.845521\n",
      "Epoch 6, loss: 17546.652533\n",
      "Epoch 7, loss: 17550.019298\n",
      "Epoch 8, loss: 17546.908654\n",
      "Epoch 9, loss: 17544.286346\n",
      "Epoch 10, loss: 17532.631199\n",
      "Epoch 11, loss: 17532.629167\n",
      "Epoch 12, loss: 17528.509158\n",
      "Epoch 13, loss: 17524.864360\n",
      "Epoch 14, loss: 17519.194408\n",
      "Epoch 15, loss: 17517.667289\n",
      "Epoch 16, loss: 17519.417653\n",
      "Epoch 17, loss: 17516.818082\n",
      "Epoch 18, loss: 17512.776513\n",
      "Epoch 19, loss: 17517.298580\n",
      "Epoch 20, loss: 17510.908317\n",
      "Epoch 21, loss: 17511.591321\n",
      "Epoch 22, loss: 17505.960669\n",
      "Epoch 23, loss: 17507.838219\n",
      "Epoch 24, loss: 17502.778941\n",
      "Epoch 25, loss: 17502.715723\n",
      "Epoch 26, loss: 17498.747400\n",
      "Epoch 27, loss: 17502.556934\n",
      "Epoch 28, loss: 17496.033051\n",
      "Epoch 29, loss: 17501.949351\n",
      "Epoch 30, loss: 17495.673880\n",
      "Epoch 31, loss: 17500.631289\n",
      "Epoch 32, loss: 17494.364898\n",
      "Epoch 33, loss: 17492.753430\n",
      "Epoch 34, loss: 17488.229062\n",
      "Epoch 35, loss: 17488.128372\n",
      "Epoch 36, loss: 17486.771357\n",
      "Epoch 37, loss: 17495.059065\n",
      "Epoch 38, loss: 17488.240418\n",
      "Epoch 39, loss: 17488.134708\n",
      "Epoch 40, loss: 17490.911549\n",
      "Epoch 41, loss: 17481.269006\n",
      "Epoch 42, loss: 17484.811387\n",
      "Epoch 43, loss: 17484.823484\n",
      "Epoch 44, loss: 17485.643578\n",
      "Epoch 45, loss: 17486.024653\n",
      "Epoch 46, loss: 17487.020370\n",
      "Epoch 47, loss: 17479.938392\n",
      "Epoch 48, loss: 17490.668528\n",
      "Epoch 49, loss: 17477.201259\n",
      "Epoch 50, loss: 17476.874307\n",
      "Epoch 51, loss: 17481.783324\n",
      "Epoch 52, loss: 17479.812473\n",
      "Epoch 53, loss: 17477.395631\n",
      "Epoch 54, loss: 17481.529106\n",
      "Epoch 55, loss: 17478.074149\n",
      "Epoch 56, loss: 17476.618320\n",
      "Epoch 57, loss: 17475.524790\n",
      "Epoch 58, loss: 17471.398253\n",
      "Epoch 59, loss: 17475.034830\n",
      "Epoch 60, loss: 17473.759212\n",
      "Epoch 61, loss: 17470.824478\n",
      "Epoch 62, loss: 17476.078231\n",
      "Epoch 63, loss: 17468.584366\n",
      "Epoch 64, loss: 17468.088760\n",
      "Epoch 65, loss: 17471.411413\n",
      "Epoch 66, loss: 17470.677513\n",
      "Epoch 67, loss: 17473.483740\n",
      "Epoch 68, loss: 17468.144354\n",
      "Epoch 69, loss: 17463.544746\n",
      "Epoch 70, loss: 17468.726331\n",
      "Epoch 71, loss: 17470.328694\n",
      "Epoch 72, loss: 17469.353364\n",
      "Epoch 73, loss: 17470.202764\n",
      "Epoch 74, loss: 17465.077559\n",
      "Epoch 75, loss: 17455.050818\n",
      "Epoch 76, loss: 17467.765095\n",
      "Epoch 77, loss: 17460.249452\n",
      "Epoch 78, loss: 17468.079332\n",
      "Epoch 79, loss: 17462.254266\n",
      "Epoch 80, loss: 17467.633416\n",
      "Epoch 81, loss: 17457.627505\n",
      "Epoch 82, loss: 17462.100763\n",
      "Epoch 83, loss: 17455.590260\n",
      "Epoch 84, loss: 17460.448740\n",
      "Epoch 85, loss: 17455.156963\n",
      "Epoch 86, loss: 17457.120376\n",
      "Epoch 87, loss: 17456.644597\n",
      "Epoch 88, loss: 17458.986698\n",
      "Epoch 89, loss: 17454.348925\n",
      "Epoch 90, loss: 17452.118051\n",
      "Epoch 91, loss: 17452.581809\n",
      "Epoch 92, loss: 17454.581847\n",
      "Epoch 93, loss: 17450.358676\n",
      "Epoch 94, loss: 17448.877682\n",
      "Epoch 95, loss: 17457.716607\n",
      "Epoch 96, loss: 17451.106091\n",
      "Epoch 97, loss: 17451.016008\n",
      "Epoch 98, loss: 17447.704560\n",
      "Epoch 99, loss: 17448.304297\n",
      "Accuracy after training for 100 epochs:  0.248\n"
     ]
    }
   ],
   "source": [
    "# Let's check how it performs on validation set\n",
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# Now, let's train more and see if it performs better\n",
    "classifier.fit(train_X, train_y, epochs=100, learning_rate=1e-4, batch_size=300, reg=1e-4)\n",
    "pred = classifier.predict(val_X)\n",
    "accuracy = multiclass_accuracy(pred, val_y)\n",
    "print(\"Accuracy after training for 100 epochs: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Как и раньше, используем кросс-валидацию для подбора гиперпараметтов.\n",
    "\n",
    "В этот раз, чтобы тренировка занимала разумное время, мы будем использовать только одно разделение на тренировочные (training) и проверочные (validation) данные.\n",
    "\n",
    "Теперь нам нужно подобрать не один, а два гиперпараметра! Не ограничивайте себя изначальными значениями в коде.  \n",
    "Добейтесь точности более чем **20%** на проверочных данных (validation data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be real number, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_5340/713632403.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;31m# than provided initially\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'best validation accuracy achieved: %f'\u001B[0m \u001B[1;33m%\u001B[0m \u001B[0mbest_val_accuracy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m: must be real number, not NoneType"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "batch_size = 300\n",
    "\n",
    "learning_rates = [1e-3, 1e-4, 1e-5]\n",
    "reg_strengths = [1e-4, 1e-5, 1e-6]\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = None\n",
    "\n",
    "# TODO use validation set to find the best hyperparameters\n",
    "# hint: for best results, you might need to try more values for learning rate and regularization strength \n",
    "# than provided initially\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Какой же точности мы добились на тестовых данных?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_5340/897742086.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mtest_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbest_classifier\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_X\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mtest_accuracy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmulticlass_accuracy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtest_pred\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtest_y\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'Linear softmax classifier test set accuracy: %f'\u001B[0m \u001B[1;33m%\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mtest_accuracy\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Linear softmax classifier test set accuracy: %f' % (test_accuracy, ))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}